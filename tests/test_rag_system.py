"""
RAGç³»ç»Ÿæµ‹è¯•

æµ‹è¯•Agentic RAGç³»ç»Ÿçš„æ ¸å¿ƒåŠŸèƒ½
"""

import asyncio
import os
import sys
from typing import Any, Dict

import pytest

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from src.rag_system import AgenticRAGSystem


class TestAgenticRAGSystem:
    """RAGç³»ç»Ÿæµ‹è¯•ç±»"""
    
    @pytest.fixture
    async def rag_system(self):
        """åˆ›å»ºRAGç³»ç»Ÿå®ä¾‹"""
        config = {
            "graph_service": {
                "storage_file": "test_data/knowledge_graph/test_graph.json"
            },
            "vector_service": {
                "storage_file": "test_data/vector_store/test_embeddings.pkl",
                "dimension": 768
            },
            "llm_service": {
                "model_name": "mock-llm",
                "embedding_dimension": 768,
                "response_delay": 0.01  # æµ‹è¯•æ—¶ä½¿ç”¨æ›´å¿«çš„å“åº”
            },
            "query_agent": {
                "max_entities": 5,
                "confidence_threshold": 0.7
            },
            "search_agent": {
                "max_results": 10,
                "similarity_threshold": 0.5
            },
            "graph_agent": {
                "max_path_length": 3,
                "max_neighbors": 5
            },
            "reasoning_agent": {
                "max_reasoning_steps": 3,
                "confidence_threshold": 0.6
            },
            "context_agent": {
                "max_context_size": 100,
                "session_timeout": 3600
            },
            "answer_agent": {
                "max_answer_length": 200,
                "include_reasoning": True,
                "include_confidence": True
            }
        }
        
        system = AgenticRAGSystem(config)
        await system.initialize()
        await system.load_mock_data()
        
        yield system
        
        await system.shutdown()
    
    @pytest.mark.asyncio
    async def test_system_initialization(self, rag_system):
        """æµ‹è¯•ç³»ç»Ÿåˆå§‹åŒ–"""
        assert rag_system._initialized == True
        assert rag_system.session_id is not None
        
        # æ£€æŸ¥æœåŠ¡çŠ¶æ€
        status = rag_system.get_system_status()
        assert status["initialized"] == True
        assert status["services"]["graph_service"]["status"] == "healthy"
        assert status["services"]["vector_service"]["status"] == "healthy"
        assert status["services"]["llm_service"]["status"] == "healthy"
    
    @pytest.mark.asyncio
    async def test_mock_data_loading(self, rag_system):
        """æµ‹è¯•æ¨¡æ‹Ÿæ•°æ®åŠ è½½"""
        status = rag_system.get_system_status()
        
        # æ£€æŸ¥å›¾æ•°æ®åº“
        graph_status = status["services"]["graph_service"]
        assert graph_status["entity_count"] > 0
        assert graph_status["relation_count"] > 0
        
        # æ£€æŸ¥å‘é‡å­˜å‚¨
        vector_status = status["services"]["vector_service"]
        assert vector_status["embedding_count"] > 0
    
    @pytest.mark.asyncio
    async def test_single_hop_query(self, rag_system):
        """æµ‹è¯•å•è·³æŸ¥è¯¢"""
        query = "å¼ ä¸‰å‚ä¸äº†å“ªä¸ªé¡¹ç›®ï¼Ÿ"
        result = await rag_system.query(query)
        
        assert result["success"] == True
        assert "answer" in result
        assert "confidence" in result
        assert "processing_time" in result
        assert result["confidence"] > 0.0
        
        # æ£€æŸ¥æ¨ç†è·¯å¾„
        reasoning_path = result.get("reasoning_path")
        assert reasoning_path is not None
        assert len(reasoning_path.get("steps", [])) > 0
    
    @pytest.mark.asyncio
    async def test_multi_hop_query(self, rag_system):
        """æµ‹è¯•å¤šè·³æŸ¥è¯¢"""
        query = "å¼ ä¸‰å‚ä¸äº†å“ªä¸ªé¡¹ç›®ï¼Ÿ"
        result = await rag_system.query(query)
        
        assert result["success"] == True
        assert "é£å¤©é¡¹ç›®" in result.get("answer", "")
        
        # æ£€æŸ¥å…ƒæ•°æ®
        metadata = result.get("metadata", {})
        assert metadata.get("total_reasoning_steps", 0) > 0
    
    @pytest.mark.asyncio
    async def test_entity_search_query(self, rag_system):
        """æµ‹è¯•å®ä½“æœç´¢æŸ¥è¯¢"""
        query = "æå››å’Œè°ä¸€èµ·å·¥ä½œï¼Ÿ"
        result = await rag_system.query(query)
        
        assert result["success"] == True
        assert len(result.get("answer", "")) > 0
    
    @pytest.mark.asyncio
    async def test_project_query(self, rag_system):
        """æµ‹è¯•é¡¹ç›®ç›¸å…³æŸ¥è¯¢"""
        query = "é£å¤©é¡¹ç›®çš„è´Ÿè´£äººæ˜¯è°ï¼Ÿ"
        result = await rag_system.query(query)
        
        assert result["success"] == True
        assert "ç‹äº”" in result.get("answer", "")
    
    @pytest.mark.asyncio
    async def test_skill_query(self, rag_system):
        """æµ‹è¯•æŠ€èƒ½ç›¸å…³æŸ¥è¯¢"""
        query = "ç‹äº”æœ‰ä»€ä¹ˆæŠ€èƒ½ï¼Ÿ"
        result = await rag_system.query(query)
        
        assert result["success"] == True
        assert len(result.get("answer", "")) > 0
    
    @pytest.mark.asyncio
    async def test_empty_query(self, rag_system):
        """æµ‹è¯•ç©ºæŸ¥è¯¢"""
        query = ""
        result = await rag_system.query(query)
        
        assert result["success"] == False
        assert "error" in result
    
    @pytest.mark.asyncio
    async def test_unknown_query(self, rag_system):
        """æµ‹è¯•æœªçŸ¥æŸ¥è¯¢"""
        query = "æœªçŸ¥å®ä½“å‚ä¸äº†ä»€ä¹ˆé¡¹ç›®ï¼Ÿ"
        result = await rag_system.query(query)
        
        # å³ä½¿æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯ï¼Œç³»ç»Ÿä¹Ÿåº”è¯¥è¿”å›ä¸€ä¸ªåˆç†çš„å“åº”
        assert "answer" in result
        assert len(result.get("answer", "")) > 0
    
    @pytest.mark.asyncio
    async def test_reasoning_path_completeness(self, rag_system):
        """æµ‹è¯•æ¨ç†è·¯å¾„å®Œæ•´æ€§"""
        query = "å¼ ä¸‰å‚ä¸äº†å“ªä¸ªé¡¹ç›®ï¼Ÿ"
        result = await rag_system.query(query)
        
        reasoning_path = result.get("reasoning_path")
        assert reasoning_path is not None
        
        # æ£€æŸ¥æ¨ç†è·¯å¾„æ˜¯å¦å®Œæ•´
        assert reasoning_path.get("query") == query
        assert len(reasoning_path.get("steps", [])) > 0
        assert reasoning_path.get("final_answer") != ""
        assert reasoning_path.get("confidence") > 0.0
    
    @pytest.mark.asyncio
    async def test_processing_time(self, rag_system):
        """æµ‹è¯•å¤„ç†æ—¶é—´"""
        query = "å¼ ä¸‰å‚ä¸äº†å“ªä¸ªé¡¹ç›®ï¼Ÿ"
        result = await rag_system.query(query)
        
        processing_time = result.get("processing_time", 0)
        assert processing_time > 0
        assert processing_time < 10.0  # åº”è¯¥åœ¨åˆç†æ—¶é—´å†…å®Œæˆ
    
    @pytest.mark.asyncio
    async def test_confidence_scores(self, rag_system):
        """æµ‹è¯•ç½®ä¿¡åº¦åˆ†æ•°"""
        query = "å¼ ä¸‰å‚ä¸äº†å“ªä¸ªé¡¹ç›®ï¼Ÿ"
        result = await rag_system.query(query)
        
        confidence = result.get("confidence", 0)
        assert 0.0 <= confidence <= 1.0
    
    @pytest.mark.asyncio
    async def test_agent_collaboration(self, rag_system):
        """æµ‹è¯•Agentåä½œ"""
        query = "å¼ ä¸‰å‚ä¸äº†å“ªä¸ªé¡¹ç›®ï¼Ÿ"
        result = await rag_system.query(query)
        
        # æ£€æŸ¥å„ä¸ªAgentçš„è´¡çŒ®
        metadata = result.get("metadata", {})
        assert metadata.get("search_results_count", 0) >= 0
        assert metadata.get("graph_results_count", 0) >= 0
        assert metadata.get("reasoning_steps_count", 0) >= 0
        assert metadata.get("total_reasoning_steps", 0) > 0


async def run_tests():
    """è¿è¡Œæµ‹è¯•"""
    print("ğŸ§ª å¼€å§‹è¿è¡ŒRAGç³»ç»Ÿæµ‹è¯•...")
    
    # åˆ›å»ºæµ‹è¯•å®ä¾‹
    config = {
        "graph_service": {
            "storage_file": "test_data/knowledge_graph/test_graph.json"
        },
        "vector_service": {
            "storage_file": "test_data/vector_store/test_embeddings.pkl",
            "dimension": 768
        },
        "llm_service": {
            "model_name": "mock-llm",
            "embedding_dimension": 768,
            "response_delay": 0.01
        }
    }
    
    rag_system = AgenticRAGSystem(config)
    
    try:
        await rag_system.initialize()
        await rag_system.load_mock_data()
        
        # è¿è¡Œæµ‹è¯•ç”¨ä¾‹
        test_cases = [
            ("å¼ ä¸‰å‚ä¸äº†å“ªä¸ªé¡¹ç›®ï¼Ÿ", "é£å¤©é¡¹ç›®"),
            ("æå››å’Œè°ä¸€èµ·å·¥ä½œï¼Ÿ", "å¼ ä¸‰"),
            ("é£å¤©é¡¹ç›®çš„è´Ÿè´£äººæ˜¯è°ï¼Ÿ", "ç‹äº”"),
            ("ç‹äº”æœ‰ä»€ä¹ˆæŠ€èƒ½ï¼Ÿ", "é¡¹ç›®ç®¡ç†")
        ]
        
        passed = 0
        total = len(test_cases)
        
        for query, expected_keyword in test_cases:
            print(f"\nğŸ” æµ‹è¯•æŸ¥è¯¢: {query}")
            result = await rag_system.query(query)
            
            if result.get("success"):
                answer = result.get("answer", "")
                if expected_keyword in answer:
                    print(f"âœ… é€šè¿‡: æ‰¾åˆ°å…³é”®è¯ '{expected_keyword}'")
                    passed += 1
                else:
                    print(f"âŒ å¤±è´¥: æœªæ‰¾åˆ°å…³é”®è¯ '{expected_keyword}'")
                    print(f"   å®é™…ç­”æ¡ˆ: {answer}")
            else:
                print(f"âŒ å¤±è´¥: æŸ¥è¯¢å¤„ç†å¤±è´¥")
                print(f"   é”™è¯¯: {result.get('error_message', 'æœªçŸ¥é”™è¯¯')}")
        
        print(f"\nğŸ“Š æµ‹è¯•ç»“æœ: {passed}/{total} é€šè¿‡")
        
        if passed == total:
            print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        else:
            print("âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥")
    
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
    
    finally:
        await rag_system.shutdown()


if __name__ == "__main__":
    asyncio.run(run_tests()) 
"""
Agentic RAG ç³»ç»Ÿä¸»ç¨‹åº

å¤šè·³é—®ç­”ç³»ç»Ÿçš„æ¼”ç¤ºç¨‹åº
"""

import asyncio
import json
from typing import Any, Dict

from src.rag_system import AgenticRAGSystem


async def main():
    """ä¸»ç¨‹åº"""
    print("ğŸš€ å¯åŠ¨ Agentic RAG å¤šè·³é—®ç­”ç³»ç»Ÿ")
    print("=" * 50)
    
    # ç³»ç»Ÿé…ç½®
    config = {
        "graph_service": {
            "storage_file": "data/knowledge_graph/graph_data.json"
        },
        "vector_service": {
            "storage_file": "data/vector_store/embeddings.pkl",
            "dimension": 768
        },
        "llm_service": {
            "model_name": "mock-llm",
            "embedding_dimension": 768,
            "response_delay": 0.1
        },
        "query_agent": {
            "max_entities": 10,
            "confidence_threshold": 0.7
        },
        "search_agent": {
            "max_results": 20,
            "similarity_threshold": 0.5
        },
        "graph_agent": {
            "max_path_length": 5,
            "max_neighbors": 10
        },
        "reasoning_agent": {
            "max_reasoning_steps": 5,
            "confidence_threshold": 0.6
        },
        "context_agent": {
            "max_context_size": 1000,
            "session_timeout": 3600
        },
        "answer_agent": {
            "max_answer_length": 500,
            "include_reasoning": True,
            "include_confidence": True
        }
    }
    
    # åˆ›å»ºRAGç³»ç»Ÿ
    rag_system = AgenticRAGSystem(config)
    
    try:
        # åˆå§‹åŒ–ç³»ç»Ÿ
        print("ğŸ“‹ åˆå§‹åŒ–ç³»ç»Ÿ...")
        await rag_system.initialize()
        
        # åŠ è½½æ¨¡æ‹Ÿæ•°æ®
        print("ğŸ“Š åŠ è½½æ¨¡æ‹Ÿæ•°æ®...")
        await rag_system.load_mock_data()
        
        # æ˜¾ç¤ºç³»ç»ŸçŠ¶æ€
        print("\nğŸ“ˆ ç³»ç»ŸçŠ¶æ€:")
        status = rag_system.get_system_status()
        print(f"  - åˆå§‹åŒ–çŠ¶æ€: {'âœ…' if status['initialized'] else 'âŒ'}")
        print(f"  - ä¼šè¯ID: {status['session_id']}")
        print(f"  - å›¾æ•°æ®åº“å®ä½“æ•°: {status['services']['graph_service']['entity_count']}")
        print(f"  - å‘é‡å­˜å‚¨æ•°é‡: {status['services']['vector_service']['embedding_count']}")
        
        # æ¼”ç¤ºæŸ¥è¯¢
        print("\nğŸ¯ å¼€å§‹æ¼”ç¤ºæŸ¥è¯¢...")
        print("=" * 50)
        
        # æµ‹è¯•æŸ¥è¯¢åˆ—è¡¨
        test_queries = [
            "å¼ ä¸‰å‚ä¸äº†å“ªä¸ªé¡¹ç›®ï¼Ÿ",
            "æå››å’Œè°ä¸€èµ·å·¥ä½œï¼Ÿ",
            "é£å¤©é¡¹ç›®çš„è´Ÿè´£äººæ˜¯è°ï¼Ÿ",
            "ç‹äº”æœ‰ä»€ä¹ˆæŠ€èƒ½ï¼Ÿ"
        ]
        
        for i, query in enumerate(test_queries, 1):
            print(f"\nğŸ” æŸ¥è¯¢ {i}: {query}")
            print("-" * 30)
            
            # æ‰§è¡ŒæŸ¥è¯¢
            result = await rag_system.query(query)
            
            # æ˜¾ç¤ºç»“æœ
            if result.get("success"):
                print(f"âœ… ç­”æ¡ˆ: {result.get('answer', '')}")
                print(f"ğŸ“Š ç½®ä¿¡åº¦: {result.get('confidence', 0):.2f}")
                print(f"â±ï¸  å¤„ç†æ—¶é—´: {result.get('processing_time', 0):.2f}ç§’")
                
                if result.get("explanation"):
                    print(f"ğŸ’¡ è§£é‡Š: {result.get('explanation')}")
                
                if result.get("reasoning_process"):
                    print(f"ğŸ§  æ¨ç†è¿‡ç¨‹:\n{result.get('reasoning_process')}")
                
                # æ˜¾ç¤ºå…ƒæ•°æ®
                metadata = result.get("metadata", {})
                print(f"ğŸ“ˆ ç»Ÿè®¡ä¿¡æ¯:")
                print(f"  - æœç´¢åˆ° {metadata.get('search_results_count', 0)} ä¸ªç»“æœ")
                print(f"  - å›¾æ•°æ®åº“è¿”å› {metadata.get('graph_results_count', 0)} ä¸ªç»“æœ")
                print(f"  - æ¨ç†æ­¥éª¤æ•°: {metadata.get('reasoning_steps_count', 0)}")
                print(f"  - æ€»æ¨ç†æ­¥éª¤: {metadata.get('total_reasoning_steps', 0)}")
            else:
                print(f"âŒ æŸ¥è¯¢å¤±è´¥: {result.get('error_message', 'æœªçŸ¥é”™è¯¯')}")
            
            print("-" * 30)
        
        # äº¤äº’å¼æŸ¥è¯¢
        print("\nğŸ® è¿›å…¥äº¤äº’æ¨¡å¼ (è¾“å…¥ 'quit' é€€å‡º)")
        print("=" * 50)
        
        while True:
            try:
                user_input = input("\nè¯·è¾“å…¥æ‚¨çš„æŸ¥è¯¢: ").strip()
                
                if user_input.lower() in ['quit', 'exit', 'é€€å‡º']:
                    break
                
                if not user_input:
                    print("è¯·è¾“å…¥æœ‰æ•ˆçš„æŸ¥è¯¢")
                    continue
                
                print(f"\nğŸ” å¤„ç†æŸ¥è¯¢: {user_input}")
                result = await rag_system.query(user_input)
                
                if result.get("success"):
                    print(f"\nâœ… ç­”æ¡ˆ: {result.get('answer', '')}")
                    print(f"ğŸ“Š ç½®ä¿¡åº¦: {result.get('confidence', 0):.2f}")
                    print(f"â±ï¸  å¤„ç†æ—¶é—´: {result.get('processing_time', 0):.2f}ç§’")
                    
                    if result.get("explanation"):
                        print(f"ğŸ’¡ è§£é‡Š: {result.get('explanation')}")
                    
                    if result.get("reasoning_process"):
                        print(f"ğŸ§  æ¨ç†è¿‡ç¨‹:\n{result.get('reasoning_process')}")
                else:
                    print(f"âŒ æŸ¥è¯¢å¤±è´¥: {result.get('error_message', 'æœªçŸ¥é”™è¯¯')}")
                
            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ ç”¨æˆ·ä¸­æ–­ï¼Œæ­£åœ¨é€€å‡º...")
                break
            except Exception as e:
                print(f"âŒ å¤„ç†æŸ¥è¯¢æ—¶å‘ç”Ÿé”™è¯¯: {e}")
    
    except Exception as e:
        print(f"âŒ ç³»ç»Ÿè¿è¡Œé”™è¯¯: {e}")
    
    finally:
        # å…³é—­ç³»ç»Ÿ
        print("\nğŸ”„ æ­£åœ¨å…³é—­ç³»ç»Ÿ...")
        await rag_system.shutdown()
        print("ğŸ‘‹ ç³»ç»Ÿå·²å…³é—­ï¼Œå†è§ï¼")


if __name__ == "__main__":
    # è¿è¡Œä¸»ç¨‹åº
    asyncio.run(main()) 